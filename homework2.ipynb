{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do': 2, 'i': 2, 'like': 1, 'green': 1, 'eggs': 1, 'and': 1, 'ham': 1}\n",
      "{'i': 3, 'am': 2, 'spam': 2, 'do': 1, 'not': 1, 'like': 1, 'that': 1, 'spamiam': 1}\n",
      "{'do': 0.3333333333333333, 'i': 0.5, 'like': 0.3333333333333333, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01, 'am': 0.99, 'spam': 0.99, 'not': 0, 'that': 0, 'spamiam': 0}\n",
      "The probability of good corpus being spam is: 5.153048105249977e-07\n",
      "The probability of bad corpus message being spam is: 0.9995920448750637\n",
      "The probability of questionable corpus being spam is: 0.111111111111111\n"
     ]
    }
   ],
   "source": [
    "'''A Spam filter based on Paul Graham's \"A Plan For Spam\".\n",
    "@author: John Baird\n",
    "@edited_on: March 8, 2019'''\n",
    "\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "bad_test = [\"i\", \"am\", \"spam\", \"spamiam\", \"do\", \"i\", \"like\", \"green\", \"spam\"]\n",
    "good_test = [\"i\", \"like\", \"eggs\", \"and\", \"green\"]\n",
    "mid_test = [\"i\", \"like\", \"eggs\", \"i\", \"do\", \"not\", \"like\", \"spam\"]\n",
    "\n",
    "def word_count(corpus):\n",
    "    #returns a dictionary with the amount of times a word occurs in a given corpus\n",
    "    word_dict = {}\n",
    "    for group in corpus:\n",
    "        for word in group:\n",
    "            word = word.lower()\n",
    "            if word in word_dict:\n",
    "                word_dict[word] = word_dict[word] + 1\n",
    "            else:\n",
    "                word_dict[word] = 1\n",
    "    return word_dict\n",
    "\n",
    "def probability_table(good, bad, ngood, nbad):\n",
    "    #returns a dictionary of probabilities based on how many times a word appears in the good or bad dictionary.\n",
    "    prob_dict = {}\n",
    "    for word in good:\n",
    "        b = 0\n",
    "        value = 0\n",
    "        g = 2 * good[word]\n",
    "        if word in bad:\n",
    "            b = bad[word]\n",
    "        if g + b > 1:\n",
    "            value = max(0.01, min(0.99, min(1.0, b / nbad) / (min(1.0, g / ngood) + min(1.0, b / nbad))))\n",
    "        prob_dict[word] = value\n",
    "    \n",
    "    for word in bad:\n",
    "        g = 0\n",
    "        value = 0\n",
    "        b = bad[word]\n",
    "        if word in good:\n",
    "            g = 2 * good[word]\n",
    "        if g + b > 1:\n",
    "            value = max(0.01, min(0.99, min(1.0, b / nbad) / (min(1.0, g / ngood) + min(1.0, b / nbad))))\n",
    "        prob_dict[word] = value\n",
    "    \n",
    "    return prob_dict\n",
    "\n",
    "def spam_odds(prob, msg):\n",
    "    #gives the odds that a message is spam\n",
    "    prod = 1\n",
    "    com_prod = 1\n",
    "    for word in msg:\n",
    "        if word in prob:\n",
    "            if prob[word] > 0:\n",
    "                prod = prod * prob[word]\n",
    "                com_prod = com_prod * (1-prob[word])\n",
    "        else:\n",
    "            prod = prod * 0.4\n",
    "            com_prod = com_prod * 0.6\n",
    "    return prod / (prod + com_prod)\n",
    "\n",
    "bad_dictionary = word_count(spam_corpus)\n",
    "good_dictionary = word_count(ham_corpus)\n",
    "test_prob = probability_table(good_dictionary, bad_dictionary, len(ham_corpus), len(spam_corpus))\n",
    "\n",
    "print(good_dictionary)\n",
    "print(bad_dictionary)\n",
    "print(test_prob)\n",
    "\n",
    "#testing spam probability on a harmless corpus\n",
    "spam_probability = spam_odds(test_prob, good_test)\n",
    "print(\"The probability of good corpus being spam is: \" + str(spam_probability))\n",
    "\n",
    "#testing spam probability on a spammy corpus\n",
    "spam_probability = spam_odds(test_prob, bad_test)\n",
    "print(\"The probability of bad corpus message being spam is: \" + str(spam_probability))\n",
    "\n",
    "#testing spam probability on a questionable corpus\n",
    "spam_probability = spam_odds(test_prob, mid_test)\n",
    "print(\"The probability of questionable corpus being spam is: \" + str(spam_probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bayesian approach as it deals in the odds that something is spam or not, as opposed to just simply marking something as spam or not spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: 0.5, True: 0.5\n",
      "False: 0.9, True: 0.1\n",
      "False: 0.952, True: 0.0476\n",
      "False: 0.01, True: 0.99\n",
      "False: 0.639, True: 0.361\n"
     ]
    }
   ],
   "source": [
    "from probability import BayesNet, enumeration_ask\n",
    "T = True\n",
    "F = False\n",
    "\n",
    "#a.\n",
    "wet_grass = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.5}),\n",
    "    ('Rain', 'Cloudy', {T: 0.8, F: 0.2}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99,(T, F): 0.9, (F, T): 0.9, (F, F): 0.0})\n",
    "])\n",
    "\n",
    "#b. There are three independent values with no conditional relations, sprinkler, cloudy, and rain\n",
    "\n",
    "#c. There is one independent value assuming implied relations, cloudy\n",
    "\n",
    "#d.\n",
    "print(enumeration_ask('Cloudy', dict(), wet_grass).show_approx())\n",
    "#According to the chart, P(Cloudy) = <.05,.05>\n",
    "\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), wet_grass).show_approx())\n",
    "#According to the chart, P(Sprinkler|Cloudy) = <.1,.9>\n",
    "\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), wet_grass).show_approx())\n",
    "''' P(Cloudy|Sprinker^notRain) = alpha * < P(C) * P(s ^ -r|C),P(-C) * P(s^-r|-C) =\n",
    "    alpha * <.5 * .02, .5* .4> =\n",
    "    alpha * <.01, .02> =\n",
    "    <.01/.21, .2/.21> =\n",
    "    <.0476, .952>\n",
    "'''\n",
    "\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), wet_grass).show_approx())\n",
    "''' P(W|c^s^r) = alpha * <P(W) * P(c^s^r|W), P(-W) * P(c^s^r|-W)> =\n",
    "    alpha * P(c) * <P(s^r|c) * P(W|s^r), P(s^r|c) * P(-W|s^R)> =\n",
    "    alpha * .5 * <.08 * .99, .08 * .01> =\n",
    "    <.0396/.04, .0004/.04> =\n",
    "    <.99, .01>\n",
    "'''\n",
    "\n",
    "#print(enumeration_ask('Cloudy', dict(WetGrass=F), wet_grass).show_approx())\n",
    "''' P(C|-w) = sum w/respect to s and sum w/respect to r (P(C) * P(s^r|C) * P(-w|s^r)) =\n",
    "    alpha * <P(C) * (P(s^r|C) * P(-w|s^R) + P(-s^r|C) * P(-w|-s^R) + P(s^-r|C) * P(-w|s^-r) +\n",
    "    P(-s^-r|C) *P(-w|-s^-r)), P(-C) * (P(s^r|C) * P(-w|s^r) + P(-s^r|C) * P(-w|-s^r) + \n",
    "    P(s^-r|C) * P(-w|s^-r) + P(-s^-r|C) * P(-w|-s^-r))> =\n",
    "    alpha * <.5 * (.08 *.01+.02*.1+.72*.1+.18*1), .5 * (.1*.01+.4*.1+.1*.1+.4*1)> =\n",
    "    alpha * <.1274, .2255> =\n",
    "    <.361,.639>\n",
    "\n",
    "'''\n",
    "#this one is only formatted funky so that the comment did not appear in the jupyter output\n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), wet_grass).show_approx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
